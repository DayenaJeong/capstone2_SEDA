{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import cv2\n",
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = hub.load(\"https://tfhub.dev/google/movenet/singlepose/lightning/4\")\n",
    "movenet = model.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(movenet, image):\n",
    "    \"\"\"이미지에서 포즈 키포인트를 추출하는 함수\"\"\"\n",
    "    input_image = tf.image.resize_with_pad(tf.expand_dims(image, axis=0), 192, 192)\n",
    "    input_image = tf.cast(input_image, dtype=tf.int32)\n",
    "    \n",
    "    # Run model inference\n",
    "    keypoints_with_scores = movenet(input_image)\n",
    "    return keypoints_with_scores['output_0'].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints_from_video_frames(video_path, movenet):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    keypoints_list = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # 현재 프레임에서 MoveNet을 사용하여 키포인트 추출\n",
    "        keypoints = run_inference(movenet, frame)\n",
    "        keypoints_list.append(keypoints)\n",
    "    \n",
    "    cap.release()\n",
    "    return keypoints_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_keypoints_from_file(keypoints_data):\n",
    "    \n",
    "    # 모든 동영상에 대한 평균 키포인트 계산\n",
    "    mean_keypoints_all_videos = []\n",
    "    for keypoints_list in keypoints_data['keypoints']:\n",
    "        # 각 동영상에 대한 키포인트 리스트에서 평균 계산\n",
    "        mean_keypoints = [[sum(pos) / len(keypoints_list) for pos in zip(*frame)] for frame in zip(*keypoints_list)]\n",
    "        mean_keypoints_all_videos.append(mean_keypoints)\n",
    "    \n",
    "    return mean_keypoints_all_videos, keypoints_data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_keypoint_changes(keypoints_data):\n",
    "    # 변경된 부분: 이미 로드된 키포인트 데이터를 직접 사용\n",
    "    # 키포인트 데이터는 각 동영상의 프레임별 키포인트 리스트를 포함하는 리스트\n",
    "\n",
    "    changes_list = []  # 변화량을 저장할 리스트 초기화\n",
    "\n",
    "    for keypoints_list in keypoints_data['keypoints']:\n",
    "        changes = []  # 개별 동영상의 키포인트 변화량을 저장할 리스트\n",
    "        prev_keypoints = None\n",
    "\n",
    "        for keypoints in keypoints_list:\n",
    "            keypoints = np.array(keypoints)\n",
    "            if prev_keypoints is not None:\n",
    "                # 현재 프레임과 이전 프레임의 키포인트 사이의 변화량 계산\n",
    "                change = np.abs(keypoints - prev_keypoints)\n",
    "                changes.append(change)\n",
    "            prev_keypoints = keypoints\n",
    "\n",
    "        # 모든 변화량의 평균 계산\n",
    "        if changes:\n",
    "            mean_changes = np.mean(changes, axis=0)\n",
    "        else:\n",
    "            # 변화량이 없는 경우, 0으로 채워진 배열 반환\n",
    "            mean_changes = np.zeros_like(keypoints_list[0])\n",
    "\n",
    "        changes_list.append(mean_changes)\n",
    "\n",
    "    return changes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(point1, point2, point3):\n",
    "    \"\"\"\n",
    "    세 점을 이용하여 두 벡터 사이의 각도를 계산합니다.\n",
    "    :param point1, point2, point3: 각 점의 좌표를 나타내는 (x, y) 튜플이나 리스트.\n",
    "    :return: 두 벡터 사이의 각도(도).\n",
    "    \"\"\"\n",
    "    # 벡터 v1과 v2 생성\n",
    "    v1 = np.array(point1) - np.array(point2)\n",
    "    v2 = np.array(point3) - np.array(point2)\n",
    "    \n",
    "    # 벡터의 내적과 노름(크기)을 사용하여 각도(라디안) 계산\n",
    "    angle_rad = np.arccos(np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2)))\n",
    "    \n",
    "    # 각도를 도로 변환\n",
    "    angle_deg = np.degrees(angle_rad)\n",
    "    \n",
    "    return angle_deg\n",
    "\n",
    "# 평균\n",
    "def calculate_angle_changes(keypoints_data, point_indices):\n",
    "    angle_changes_list = []\n",
    "    for keypoints_list in keypoints_data['keypoints']:\n",
    "        angles = []\n",
    "        for frame_keypoints in keypoints_list:\n",
    "            # 키포인트 데이터가 충분한지 확인\n",
    "            if len(frame_keypoints) > max(point_indices):\n",
    "                p1 = frame_keypoints[point_indices[0]][:2]  # x, y 좌표만 사용\n",
    "                p2 = frame_keypoints[point_indices[1]][:2]\n",
    "                p3 = frame_keypoints[point_indices[2]][:2]\n",
    "                angle = calculate_angle(p1, p2, p3)\n",
    "                angles.append(angle)\n",
    "            else:\n",
    "                # 충분한 데이터가 없는 경우 계산에서 제외\n",
    "                continue\n",
    "        \n",
    "        if angles:  # 각도 데이터가 있을 경우에만 계산\n",
    "            angle_changes = np.abs(np.diff(angles))\n",
    "            mean_angle_change = np.mean(angle_changes)\n",
    "            angle_changes_list.append(mean_angle_change)\n",
    "        else:\n",
    "            # 각도 데이터가 없는 경우 0으로 처리\n",
    "            angle_changes_list.append(0)\n",
    "    \n",
    "    return np.array(angle_changes_list)\n",
    "\n",
    "# 최솟값\n",
    "def calculate_min_angle_changes(keypoints_data, point_indices):\n",
    "    min_angle_changes_list = []\n",
    "    for keypoints_list in keypoints_data['keypoints']:\n",
    "        angles = []\n",
    "        for frame_keypoints in keypoints_list:\n",
    "            if len(frame_keypoints) > max(point_indices):\n",
    "                p1 = frame_keypoints[point_indices[0]][:2]  # x, y 좌표만 사용\n",
    "                p2 = frame_keypoints[point_indices[1]][:2]\n",
    "                p3 = frame_keypoints[point_indices[2]][:2]\n",
    "                angle = calculate_angle(p1, p2, p3)\n",
    "                angles.append(angle)\n",
    "\n",
    "        if angles:\n",
    "            angle_changes = np.abs(np.diff(angles))\n",
    "            min_angle_change = np.min(angle_changes) if len(angle_changes) > 0 else 0\n",
    "            min_angle_changes_list.append(min_angle_change)\n",
    "        else:\n",
    "            min_angle_changes_list.append(0)\n",
    "    \n",
    "    return np.array(min_angle_changes_list)\n",
    "\n",
    "# 최댓값\n",
    "def calculate_max_angle_changes(keypoints_data, point_indices):\n",
    "    max_angle_changes_list = []\n",
    "    for keypoints_list in keypoints_data['keypoints']:\n",
    "        angles = []\n",
    "        for frame_keypoints in keypoints_list:\n",
    "            if len(frame_keypoints) > max(point_indices):\n",
    "                p1 = frame_keypoints[point_indices[0]][:2]  # x, y 좌표만 사용\n",
    "                p2 = frame_keypoints[point_indices[1]][:2]\n",
    "                p3 = frame_keypoints[point_indices[2]][:2]\n",
    "                angle = calculate_angle(p1, p2, p3)\n",
    "                angles.append(angle)\n",
    "\n",
    "        if angles:\n",
    "            angle_changes = np.abs(np.diff(angles))\n",
    "            max_angle_change = np.max(angle_changes) if len(angle_changes) > 0 else 0\n",
    "            max_angle_changes_list.append(max_angle_change)\n",
    "        else:\n",
    "            max_angle_changes_list.append(0)\n",
    "    \n",
    "    return np.array(max_angle_changes_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_enhanced_autocorrelation_features(keypoints_data):\n",
    "    features_list = []  # 각 동영상의 향상된 자기상관성 특성을 저장할 리스트\n",
    "\n",
    "    for keypoints_list in keypoints_data['keypoints']:\n",
    "        changes = []\n",
    "        prev_keypoints = None\n",
    "        for keypoints in keypoints_list:\n",
    "            keypoints = np.array(keypoints)\n",
    "            if prev_keypoints is not None:\n",
    "                change = np.linalg.norm(keypoints - prev_keypoints)\n",
    "                changes.append(change)\n",
    "            prev_keypoints = keypoints\n",
    "\n",
    "        if changes:\n",
    "            changes = np.array(changes)\n",
    "            autocorrelation = np.correlate(changes - np.mean(changes), changes - np.mean(changes), mode='full')\n",
    "            autocorrelation = autocorrelation[autocorrelation.size // 2:]  # 자기상관성 값 중 양의 지연만 고려\n",
    "\n",
    "            # 향상된 특성 계산\n",
    "            mean_autocorrelation = np.mean(autocorrelation)\n",
    "            std_autocorrelation = np.std(autocorrelation)\n",
    "            peak_count = np.sum(autocorrelation > (mean_autocorrelation + std_autocorrelation))  # 평균 이상의 피크 수\n",
    "\n",
    "            features = [mean_autocorrelation, std_autocorrelation, peak_count]\n",
    "        else:\n",
    "            features = [0, 0, 0]\n",
    "\n",
    "        features_list.append(features)\n",
    "\n",
    "    return features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_features_per_video(features, labels):\n",
    "    features_per_video = []\n",
    "    labels_per_video = []\n",
    "    \n",
    "    current_video_label = None\n",
    "    current_video_features = []\n",
    "    \n",
    "    for feature_vector, label in zip(features, labels):\n",
    "        if current_video_label is None:\n",
    "            current_video_label = label\n",
    "        \n",
    "        if label == current_video_label:\n",
    "            current_video_features.append(feature_vector)\n",
    "        else:\n",
    "            # 이전 동영상의 특징들의 평균을 계산\n",
    "            average_features = np.mean(current_video_features, axis=0)\n",
    "            features_per_video.append(average_features)\n",
    "            labels_per_video.append(current_video_label)\n",
    "            \n",
    "            # 새 동영상의 데이터로 리셋\n",
    "            current_video_features = [feature_vector]\n",
    "            current_video_label = label\n",
    "    \n",
    "    # 마지막 동영상 처리\n",
    "    if current_video_features:\n",
    "        average_features = np.mean(current_video_features, axis=0)\n",
    "        features_per_video.append(average_features)\n",
    "        labels_per_video.append(current_video_label)\n",
    "    \n",
    "    return np.array(features_per_video), np.array(labels_per_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_file_path = '/Users/diana/Desktop/BabyposeModel/capstone2_SEDA/keypoints_data_augmented.pkl'\n",
    "\n",
    "# pickle 파일 로드\n",
    "with open(pkl_file_path, 'rb') as f:\n",
    "     keypoints_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_keypoints_all_videos, labels = calculate_mean_keypoints_from_file(keypoints_data)\n",
    "changes_list = calculate_keypoint_changes(keypoints_data)\n",
    "autocorrelation_list = calculate_enhanced_autocorrelation_features(keypoints_data)\n",
    "\n",
    "back_angle_changes_list1 = calculate_angle_changes(keypoints_data, (6,12,16))\n",
    "back_angle_changes_list2 = calculate_angle_changes(keypoints_data, (5,11,15))\n",
    "head_angle_changes_list1 = calculate_angle_changes(keypoints_data, (0,6,12))\n",
    "head_angle_changes_list2 = calculate_angle_changes(keypoints_data, (0,5,11))\n",
    "leg_angle_changes_list1 = calculate_angle_changes(keypoints_data, (12,14,16))\n",
    "leg_angle_changes_list2 = calculate_angle_changes(keypoints_data, (11,13,15))\n",
    "eye_angle_changes_list1 = calculate_angle_changes(keypoints_data, (1,5,9))\n",
    "eye_angle_changes_list2 = calculate_angle_changes(keypoints_data, (2,6,10))\n",
    "strech_angle_changes_list1 = calculate_angle_changes(keypoints_data, (5,8,10))\n",
    "strech_angle_changes_list2 = calculate_angle_changes(keypoints_data, (6,7,9))\n",
    "finger_angle_changes_list1 = calculate_angle_changes(keypoints_data, (0,8,10))\n",
    "finger_angle_changes_list2 = calculate_angle_changes(keypoints_data, (0,7,9))\n",
    "\n",
    "back_min_angle_changes_list1 = calculate_min_angle_changes(keypoints_data, (6,12,16))\n",
    "back_min_angle_changes_list2 = calculate_min_angle_changes(keypoints_data, (5,11,15))\n",
    "head_min_angle_changes_list1 = calculate_min_angle_changes(keypoints_data, (0,6,12))\n",
    "head_min_angle_changes_list2 = calculate_min_angle_changes(keypoints_data, (0,5,11))\n",
    "leg_min_angle_changes_list1 = calculate_min_angle_changes(keypoints_data, (12,14,16))\n",
    "leg_min_angle_changes_list2 = calculate_min_angle_changes(keypoints_data, (11,13,15))\n",
    "eye_min_angle_changes_list1 = calculate_min_angle_changes(keypoints_data, (1,5,9))\n",
    "eye_min_angle_changes_list2 = calculate_min_angle_changes(keypoints_data, (2,6,10))\n",
    "strech_min_angle_changes_list1 = calculate_min_angle_changes(keypoints_data, (5,8,10))\n",
    "strech_min_angle_changes_list2 = calculate_min_angle_changes(keypoints_data, (6,7,9))\n",
    "finger_min_angle_changes_list1 = calculate_min_angle_changes(keypoints_data, (0,8,10))\n",
    "finger_min_angle_changes_list2 = calculate_min_angle_changes(keypoints_data, (0,7,9))\n",
    "\n",
    "back_max_angle_changes_list1 = calculate_max_angle_changes(keypoints_data, (6,12,16))\n",
    "back_max_angle_changes_list2 = calculate_max_angle_changes(keypoints_data, (5,11,15))\n",
    "head_max_angle_changes_list1 = calculate_max_angle_changes(keypoints_data, (0,6,12))\n",
    "head_max_angle_changes_list2 = calculate_max_angle_changes(keypoints_data, (0,5,11))\n",
    "leg_max_angle_changes_list1 = calculate_max_angle_changes(keypoints_data, (12,14,16))\n",
    "leg_max_angle_changes_list2 = calculate_max_angle_changes(keypoints_data, (11,13,15))\n",
    "eye_max_angle_changes_list1 = calculate_max_angle_changes(keypoints_data, (1,5,9))\n",
    "eye_max_angle_changes_list2 = calculate_max_angle_changes(keypoints_data, (2,6,10))\n",
    "strech_max_angle_changes_list1 = calculate_max_angle_changes(keypoints_data, (5,8,10))\n",
    "strech_max_angle_changes_list2 = calculate_max_angle_changes(keypoints_data, (6,7,9))\n",
    "finger_max_angle_changes_list1 = calculate_max_angle_changes(keypoints_data, (0,8,10))\n",
    "finger_max_angle_changes_list2 = calculate_max_angle_changes(keypoints_data, (0,7,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "mean_keypoints_all_videos = np.array(mean_keypoints_all_videos)\n",
    "changes_list = np.array(changes_list)\n",
    "autocorrelation_list = np.array(autocorrelation_list)\n",
    "\n",
    "for i in range(len(mean_keypoints_all_videos)):\n",
    "    combined_feature = np.concatenate([mean_keypoints_all_videos[i].flatten(), changes_list[i].flatten(), autocorrelation_list[i].flatten(),\n",
    "    # fft_features_list[i].flatten(),\n",
    "    [back_max_angle_changes_list1[i] - back_min_angle_changes_list1[i],\n",
    "    back_max_angle_changes_list2[i] - back_min_angle_changes_list2[i],\n",
    "    head_max_angle_changes_list1[i] - head_min_angle_changes_list1[i],\n",
    "    head_max_angle_changes_list2[i] - head_min_angle_changes_list2[i],\n",
    "    leg_max_angle_changes_list1[i] - leg_min_angle_changes_list1[i],\n",
    "    leg_max_angle_changes_list2[i] - leg_min_angle_changes_list2[i],\n",
    "    eye_max_angle_changes_list1[i] - eye_min_angle_changes_list1[i],\n",
    "    eye_max_angle_changes_list2[i] - eye_min_angle_changes_list2[i],\n",
    "    strech_max_angle_changes_list1[i] - strech_min_angle_changes_list1[i],\n",
    "    strech_max_angle_changes_list2[i] - strech_min_angle_changes_list2[i],\n",
    "    finger_max_angle_changes_list1[i] - finger_min_angle_changes_list1[i],\n",
    "    finger_max_angle_changes_list2[i] - finger_min_angle_changes_list2[i]]])\n",
    "    \n",
    "    features.append(combined_feature)\n",
    "\n",
    "# 특징과 레이블을 동영상 단위로 평균 내기\n",
    "features_per_video, labels_per_video = average_features_per_video(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# pickle 파일 로드 (예: 동영상 프레임별 특징 및 레이블이 포함된 데이터)\n",
    "with open('keypoints_data_augmented.pkl', 'rb') as f:\n",
    "    keypoints_data = pickle.load(f)\n",
    "\n",
    "# 동영상 별 특성 집계 (예를 들어 평균을 사용)\n",
    "video_features = []\n",
    "video_labels = []\n",
    "current_video_features = []\n",
    "current_video_label = None\n",
    "\n",
    "for features, label in zip(keypoints_data['keypoints'], keypoints_data['labels']):\n",
    "    if current_video_label is None:\n",
    "        current_video_label = label\n",
    "    if label == current_video_label:\n",
    "        current_video_features.append(features)\n",
    "    else:\n",
    "        if current_video_features:  # 비어있지 않은 경우에만 평균 계산\n",
    "            # 최대 길이 찾기\n",
    "            max_length = max(len(f) for f in current_video_features)\n",
    "            # 모든 특징을 최대 길이에 맞추기\n",
    "            padded_features = [np.pad(f, (0, max_length - len(f)), 'constant', constant_values=0) for f in current_video_features]\n",
    "            # 안전하게 평균 계산\n",
    "            video_features.append(np.mean(padded_features, axis=0))\n",
    "            video_labels.append(current_video_label)\n",
    "        \n",
    "        # 다음 동영상 처리\n",
    "        current_video_features = [features]\n",
    "        current_video_label = label\n",
    "\n",
    "# 마지막 동영상 처리\n",
    "if current_video_features:\n",
    "    # 최대 길이 찾기\n",
    "    max_length = max(len(f) for f in current_video_features)\n",
    "    # 모든 특징을 최대 길이에 맞추기\n",
    "    padded_features = [np.pad(f, (0, max_length - len(f)), 'constant', constant_values=0) for f in current_video_features]\n",
    "    # 안전하게 평균 계산\n",
    "    video_features.append(np.mean(padded_features, axis=0))\n",
    "    video_labels.append(current_video_label)\n",
    "\n",
    "# 데이터 스케일링 및 분할\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(video_features)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_scaled, video_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Optuna를 사용한 SVM 최적화\n",
    "def objective(trial):\n",
    "    c = trial.suggest_loguniform('C', 1e-3, 1e3)\n",
    "    gamma = trial.suggest_loguniform('gamma', 1e-3, 1e3)\n",
    "    kernel = trial.suggest_categorical('kernel', ['rbf', 'poly', 'sigmoid'])\n",
    "\n",
    "    svm = SVC(C=c, gamma=gamma, kernel=kernel, random_state=42)\n",
    "    svm.fit(X_train, y_train)\n",
    "    return svm.score(X_test, y_test)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print(f'Best parameters: {study.best_params}')\n",
    "print(f'Test Accuracy: {study.best_trial.value:.2f}%')\n",
    "\n",
    "# 최적의 파라미터로 모델 재학습 및 저장\n",
    "best_model = SVC(**study.best_params, random_state=42)\n",
    "best_model.fit(features_scaled, video_labels)\n",
    "with open('svm_model_video1.pkl', 'wb') as f:\n",
    "    pickle.dump({'model': best_model, 'scaler': scaler}, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
