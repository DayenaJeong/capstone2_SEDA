import streamlit as st
import cv2
import numpy as np
import tensorflow as tf
import tensorflow_hub as hub
from sklearn import svm
from sklearn.preprocessing import StandardScaler
import pickle
from collections import Counter
import tempfile
import imageio
import os


# í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ í•¨ìˆ˜
def run_inference(movenet, image):
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    input_image = tf.image.resize_with_pad(tf.expand_dims(image, axis=0), 192, 192)
    # ëª¨ë¸ì´ int32 ì…ë ¥ì„ ìš”êµ¬í•˜ëŠ” ê²½ìš°
    input_image = tf.cast(input_image, dtype=tf.int32)
    outputs = movenet(input_image)
    return outputs['output_0'].numpy()[0]

# ë¹„ë””ì˜¤ì—ì„œ í”„ë ˆì„ë³„ í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ
def extract_keypoints_from_video_frames(video_path, movenet):
    cap = cv2.VideoCapture(video_path)
    keypoints_list = []
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        keypoints = run_inference(movenet, frame)
        keypoints_list.append(keypoints)
    cap.release()
    return {'keypoints': keypoints_list, 'labels': []}


def calculate_mean_keypoints_from_file(keypoints_data):

    # ëª¨ë“  ë™ì˜ìƒì— ëŒ€í•œ í‰ê·  í‚¤í¬ì¸íŠ¸ ê³„ì‚°
    mean_keypoints_all_videos = []
    for keypoints_list in keypoints_data['keypoints']:
        # ê° ë™ì˜ìƒì— ëŒ€í•œ í‚¤í¬ì¸íŠ¸ ë¦¬ìŠ¤íŠ¸ì—ì„œ í‰ê·  ê³„ì‚°
        mean_keypoints = [[sum(pos) / len(keypoints_list) for pos in zip(*frame)] for frame in zip(*keypoints_list)]
        mean_keypoints_all_videos.append(mean_keypoints)

    return mean_keypoints_all_videos, keypoints_data['labels']

def extract_and_augment_keypoints(video_path, movenet, sampling_rate=2, additional_sampling_rate=3):
    cap = cv2.VideoCapture(video_path)
    original_keypoints = []
    flipped_keypoints = []
    sampled_keypoints = []  # sampling_rate=2ì— ëŒ€í•œ í‚¤í¬ì¸íŠ¸
    additional_sampled_keypoints = []  # ì¶”ê°€ì ì¸ sampling_rate=3ì— ëŒ€í•œ í‚¤í¬ì¸íŠ¸
    additional_sampled_keypoints_2 = []
    frame_count = 0

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        # ì›ë³¸ í”„ë ˆì„ì—ì„œ í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ
        keypoints = run_inference(movenet, frame)
        original_keypoints.append(keypoints)

        # í”„ë ˆì„ì„ ì¢Œìš° ë°˜ì „í•˜ì—¬ í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ
        frame_flipped = cv2.flip(frame, 1)
        keypoints_flipped = run_inference(movenet, frame_flipped)
        flipped_keypoints.append(keypoints_flipped)

        # ê¸°ì¡´ ì‹œê°„ì  ì¦ê°•: sampling_rate=2ì— ë”°ë¼ í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ
        if frame_count % sampling_rate == 0:
            sampled_keypoints.append(keypoints)
        
        # ì¶”ê°€ì ì¸ ì‹œê°„ì  ì¦ê°•: additional_sampling_rate=3ì— ë”°ë¼ í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ
        if frame_count % additional_sampling_rate == 0:
            additional_sampled_keypoints.append(keypoints)
            
        # ì¶”ê°€ì ì¸ ì‹œê°„ì  ì¦ê°•: additional_sampling_rate=3ì— ë”°ë¼ í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ
        if frame_count % 4 == 0:
            additional_sampled_keypoints_2.append(keypoints)

        frame_count += 1
    
    cap.release()
    # ëª¨ë“  í‚¤í¬ì¸íŠ¸ ë¦¬ìŠ¤íŠ¸ì™€ ì¶”ê°€ì ì¸ ìƒ˜í”Œë§ëœ í‚¤í¬ì¸íŠ¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    return original_keypoints, flipped_keypoints, sampled_keypoints, additional_sampled_keypoints, additional_sampled_keypoints_2

def calculate_keypoint_changes(keypoints_data):
    # ë³€ê²½ëœ ë¶€ë¶„: ì´ë¯¸ ë¡œë“œëœ í‚¤í¬ì¸íŠ¸ ë°ì´í„°ë¥¼ ì§ì ‘ ì‚¬ìš©
    # í‚¤í¬ì¸íŠ¸ ë°ì´í„°ëŠ” ê° ë™ì˜ìƒì˜ í”„ë ˆì„ë³„ í‚¤í¬ì¸íŠ¸ ë¦¬ìŠ¤íŠ¸ë¥¼ í¬í•¨í•˜ëŠ” ë¦¬ìŠ¤íŠ¸

    changes_list = []  # ë³€í™”ëŸ‰ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”

    for keypoints_list in keypoints_data['keypoints']:
        changes = []  # ê°œë³„ ë™ì˜ìƒì˜ í‚¤í¬ì¸íŠ¸ ë³€í™”ëŸ‰ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
        prev_keypoints = None

        for keypoints in keypoints_list:
            keypoints = np.array(keypoints)
            if prev_keypoints is not None:
                # í˜„ì¬ í”„ë ˆì„ê³¼ ì´ì „ í”„ë ˆì„ì˜ í‚¤í¬ì¸íŠ¸ ì‚¬ì´ì˜ ë³€í™”ëŸ‰ ê³„ì‚°
                change = np.abs(keypoints - prev_keypoints)
                changes.append(change)
            prev_keypoints = keypoints

        # ëª¨ë“  ë³€í™”ëŸ‰ì˜ í‰ê·  ê³„ì‚°
        if changes:
            mean_changes = np.mean(changes, axis=0)
        else:
            # ë³€í™”ëŸ‰ì´ ì—†ëŠ” ê²½ìš°, 0ìœ¼ë¡œ ì±„ì›Œì§„ ë°°ì—´ ë°˜í™˜
            mean_changes = np.zeros_like(keypoints_list[0])

        changes_list.append(mean_changes)

    return changes_list

def calculate_angle(point1, point2, point3):
    """
    ì„¸ ì ì„ ì´ìš©í•˜ì—¬ ë‘ ë²¡í„° ì‚¬ì´ì˜ ê°ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    :param point1, point2, point3: ê° ì ì˜ ì¢Œí‘œë¥¼ ë‚˜íƒ€ë‚´ëŠ” (x, y) íŠœí”Œì´ë‚˜ ë¦¬ìŠ¤íŠ¸.
    :return: ë‘ ë²¡í„° ì‚¬ì´ì˜ ê°ë„(ë„).
    """
    # ë²¡í„° v1ê³¼ v2 ìƒì„±
    v1 = np.array(point1) - np.array(point2)
    v2 = np.array(point3) - np.array(point2)

    # ë²¡í„°ì˜ ë‚´ì ê³¼ ë…¸ë¦„(í¬ê¸°)ì„ ì‚¬ìš©í•˜ì—¬ ê°ë„(ë¼ë””ì•ˆ) ê³„ì‚°
    angle_rad = np.arccos(np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2)))

    # ê°ë„ë¥¼ ë„ë¡œ ë³€í™˜
    angle_deg = np.degrees(angle_rad)

    return angle_deg

# í‰ê· 
def calculate_angle_changes(keypoints_data, point_indices):
    angle_changes_list = []
    for keypoints_list in keypoints_data['keypoints']:
        angles = []
        for frame_keypoints in keypoints_list:
            # í‚¤í¬ì¸íŠ¸ ë°ì´í„°ê°€ ì¶©ë¶„í•œì§€ í™•ì¸
            if len(frame_keypoints) > max(point_indices):
                p1 = frame_keypoints[point_indices[0]][:2]  # x, y ì¢Œí‘œë§Œ ì‚¬ìš©
                p2 = frame_keypoints[point_indices[1]][:2]
                p3 = frame_keypoints[point_indices[2]][:2]
                angle = calculate_angle(p1, p2, p3)
                angles.append(angle)
            else:
                # ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° ê³„ì‚°ì—ì„œ ì œì™¸
                continue

        if angles:  # ê°ë„ ë°ì´í„°ê°€ ìˆì„ ê²½ìš°ì—ë§Œ ê³„ì‚°
            angle_changes = np.abs(np.diff(angles))
            mean_angle_change = np.mean(angle_changes)
            angle_changes_list.append(mean_angle_change)
        else:
            # ê°ë„ ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° 0ìœ¼ë¡œ ì²˜ë¦¬
            angle_changes_list.append(0)

    return np.array(angle_changes_list)

# ìµœì†Ÿê°’
def calculate_min_angle_changes(keypoints_data, point_indices):
    min_angle_changes_list = []
    for keypoints_list in keypoints_data['keypoints']:
        angles = []
        for frame_keypoints in keypoints_list:
            if len(frame_keypoints) > max(point_indices):
                p1 = frame_keypoints[point_indices[0]][:2]  # x, y ì¢Œí‘œë§Œ ì‚¬ìš©
                p2 = frame_keypoints[point_indices[1]][:2]
                p3 = frame_keypoints[point_indices[2]][:2]
                angle = calculate_angle(p1, p2, p3)
                angles.append(angle)

        if angles:
            angle_changes = np.abs(np.diff(angles))
            min_angle_change = np.min(angle_changes) if len(angle_changes) > 0 else 0
            min_angle_changes_list.append(min_angle_change)
        else:
            min_angle_changes_list.append(0)

    return np.array(min_angle_changes_list)

# ìµœëŒ“ê°’
def calculate_max_angle_changes(keypoints_data, point_indices):
    max_angle_changes_list = []
    for keypoints_list in keypoints_data['keypoints']:
        angles = []
        for frame_keypoints in keypoints_list:
            if len(frame_keypoints) > max(point_indices):
                p1 = frame_keypoints[point_indices[0]][:2]  # x, y ì¢Œí‘œë§Œ ì‚¬ìš©
                p2 = frame_keypoints[point_indices[1]][:2]
                p3 = frame_keypoints[point_indices[2]][:2]
                angle = calculate_angle(p1, p2, p3)
                angles.append(angle)

        if angles:
            angle_changes = np.abs(np.diff(angles))
            max_angle_change = np.max(angle_changes) if len(angle_changes) > 0 else 0
            max_angle_changes_list.append(max_angle_change)
        else:
            max_angle_changes_list.append(0)

    return np.array(max_angle_changes_list)

def calculate_enhanced_autocorrelation_features(keypoints_data):
    features_list = []  # ê° ë™ì˜ìƒì˜ í–¥ìƒëœ ìê¸°ìƒê´€ì„± íŠ¹ì„±ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸

    for keypoints_list in keypoints_data['keypoints']:
        changes = []
        prev_keypoints = None
        for keypoints in keypoints_list:
            keypoints = np.array(keypoints)
            if prev_keypoints is not None:
                change = np.linalg.norm(keypoints - prev_keypoints)
                changes.append(change)
            prev_keypoints = keypoints

        if changes:
            changes = np.array(changes)
            autocorrelation = np.correlate(changes - np.mean(changes), changes - np.mean(changes), mode='full')
            autocorrelation = autocorrelation[autocorrelation.size // 2:]  # ìê¸°ìƒê´€ì„± ê°’ ì¤‘ ì–‘ì˜ ì§€ì—°ë§Œ ê³ ë ¤

            # í–¥ìƒëœ íŠ¹ì„± ê³„ì‚°
            mean_autocorrelation = np.mean(autocorrelation)
            std_autocorrelation = np.std(autocorrelation)
            peak_count = np.sum(autocorrelation > (mean_autocorrelation + std_autocorrelation))  # í‰ê·  ì´ìƒì˜ í”¼í¬ ìˆ˜

            features = [mean_autocorrelation, std_autocorrelation, peak_count]
        else:
            features = [0, 0, 0]

        features_list.append(features)

    return features_list

# ì¶”ì¶œëœ í‚¤í¬ì¸íŠ¸ë¡œë¶€í„° íŠ¹ì§• ê³„ì‚°
def calculate_features(keypoints_data):
    # í‚¤í¬ì¸íŠ¸ì—ì„œ í‰ê· , ë³€í™”ëŸ‰, ìê¸°ìƒê´€ì„± ë“±ì˜ íŠ¹ì§• ê³„ì‚°
    mean_keypoints_all_videos, labels = calculate_mean_keypoints_from_file(keypoints_data)
    changes_list = calculate_keypoint_changes(keypoints_data)
    autocorrelation_list = calculate_enhanced_autocorrelation_features(keypoints_data)

    back_min_angle_changes_list1 = calculate_min_angle_changes(keypoints_data, (6,12,16))
    back_min_angle_changes_list2 = calculate_min_angle_changes(keypoints_data, (5,11,15))
    head_min_angle_changes_list1 = calculate_min_angle_changes(keypoints_data, (0,6,12))
    head_min_angle_changes_list2 = calculate_min_angle_changes(keypoints_data, (0,5,11))
    leg_min_angle_changes_list1 = calculate_min_angle_changes(keypoints_data, (12,14,16))
    leg_min_angle_changes_list2 = calculate_min_angle_changes(keypoints_data, (11,13,15))
    eye_min_angle_changes_list1 = calculate_min_angle_changes(keypoints_data, (1,5,9))
    eye_min_angle_changes_list2 = calculate_min_angle_changes(keypoints_data, (2,6,10))
    strech_min_angle_changes_list1 = calculate_min_angle_changes(keypoints_data, (5,8,10))
    strech_min_angle_changes_list2 = calculate_min_angle_changes(keypoints_data, (6,7,9))
    finger_min_angle_changes_list1 = calculate_min_angle_changes(keypoints_data, (0,8,10))
    finger_min_angle_changes_list2 = calculate_min_angle_changes(keypoints_data, (0,7,9))

    back_max_angle_changes_list1 = calculate_max_angle_changes(keypoints_data, (6,12,16))
    back_max_angle_changes_list2 = calculate_max_angle_changes(keypoints_data, (5,11,15))
    head_max_angle_changes_list1 = calculate_max_angle_changes(keypoints_data, (0,6,12))
    head_max_angle_changes_list2 = calculate_max_angle_changes(keypoints_data, (0,5,11))
    leg_max_angle_changes_list1 = calculate_max_angle_changes(keypoints_data, (12,14,16))
    leg_max_angle_changes_list2 = calculate_max_angle_changes(keypoints_data, (11,13,15))
    eye_max_angle_changes_list1 = calculate_max_angle_changes(keypoints_data, (1,5,9))
    eye_max_angle_changes_list2 = calculate_max_angle_changes(keypoints_data, (2,6,10))
    strech_max_angle_changes_list1 = calculate_max_angle_changes(keypoints_data, (5,8,10))
    strech_max_angle_changes_list2 = calculate_max_angle_changes(keypoints_data, (6,7,9))
    finger_max_angle_changes_list1 = calculate_max_angle_changes(keypoints_data, (0,8,10))
    finger_max_angle_changes_list2 = calculate_max_angle_changes(keypoints_data, (0,7,9))

    # ê³„ì‚°ëœ íŠ¹ì§•ì„ í•˜ë‚˜ì˜ ë°°ì—´ë¡œ ë³‘í•©
    features = []
    mean_keypoints_all_videos = np.array(mean_keypoints_all_videos)
    changes_list = np.array(changes_list)
    autocorrelation_list = np.array(autocorrelation_list)
    for i in range(len(mean_keypoints_all_videos)):
        combined_feature = np.concatenate([mean_keypoints_all_videos[i].flatten(), changes_list[i].flatten(), autocorrelation_list[i].flatten(),
        # fft_features_list[i].flatten(),
        [back_max_angle_changes_list1[i] - back_min_angle_changes_list1[i],
        back_max_angle_changes_list2[i] - back_min_angle_changes_list2[i],
        head_max_angle_changes_list1[i] - head_min_angle_changes_list1[i],
        head_max_angle_changes_list2[i] - head_min_angle_changes_list2[i],
        leg_max_angle_changes_list1[i] - leg_min_angle_changes_list1[i],
        leg_max_angle_changes_list2[i] - leg_min_angle_changes_list2[i],
        eye_max_angle_changes_list1[i] - eye_min_angle_changes_list1[i],
        eye_max_angle_changes_list2[i] - eye_min_angle_changes_list2[i],
        strech_max_angle_changes_list1[i] - strech_min_angle_changes_list1[i],
        strech_max_angle_changes_list2[i] - strech_min_angle_changes_list2[i],
        finger_max_angle_changes_list1[i] - finger_min_angle_changes_list1[i],
        finger_max_angle_changes_list2[i] - finger_min_angle_changes_list2[i]]])

        features.append(combined_feature)
    return np.array(features), labels

st.title("ğŸ‘¶ğŸ» BabySign Interpreter ğŸ‘¼ğŸ»")
st.subheader("âœ¨ ë¹„ë””ì˜¤ í¬ì¦ˆ ë¶„ì„ì„ í†µí•œ ì•„ê¸° ì†Œí†µ í•´ì„ ì•± âœ¨")
#st.write("â¬‡ï¸ ê¶ê¸ˆí–ˆë˜ ì•„ì´ì˜ í–‰ë™ì„ ë¶„ì„í•˜ê¸° ìœ„í•´ ì—…ë¡œë“œ í•´ì£¼ì„¸ìš” â¬‡ï¸")

uploaded_file = st.file_uploader("â¬‡ï¸ ê¶ê¸ˆí–ˆë˜ ì•„ì´ì˜ í–‰ë™ì„ ë¶„ì„í•˜ê¸° ìœ„í•´ ì˜ìƒì„ ì—…ë¡œë“œ í•´ì£¼ì„¸ìš”! (mp4, avi, movë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤â˜ºï¸) â¬‡ï¸", type=["mp4", "avi", "mov"])


# ë ˆì´ë¸” ë§¤í•‘ ë”•ì…”ë„ˆë¦¬
label_descriptions = {
    0: ('ìì„¸ë¥¼ ë°”ê¾¸ê³  ì‹¶ì–´ìš”! ì—¬ê¸°ì—ì„œ ë²—ì–´ë‚˜ê³  ì‹¶ì–´ìš” ğŸ˜£', """
        \n- ë¶ˆí¸í•¨ì´ë‚˜ ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ëŠë‚„ ë•Œ ì•„ì´ê°€ ì·¨í•  ìˆ˜ ìˆëŠ” í¬ì¦ˆì…ë‹ˆë‹¤.
        \n- ìœ„ì‹ë„ ì—­ë¥˜ë‚˜ ë³µí†µ ê°™ì€ ì‹ ì²´ì  ë¶ˆí¸ì„ í˜¸ì†Œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        \n- ì´ëŸ° ë™ì‘ì€ ì£¼ë¡œ ìˆ˜ìœ  í›„ ë˜ëŠ” ë¶ˆí¸ì„ ëŠë¼ëŠ” ìƒí™©ì—ì„œ ë‚˜íƒ€ë‚  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        \n- ì´ëŸ° í–‰ë™ì„ ë³´ì´ë©´ ì•„ì´ë¥¼ ì„¸ì›Œ í¸ì•ˆí•˜ê²Œ í•´ ì£¼ì‹œê³ , ì‘ì€ ì–‘ì„ ì—¬ëŸ¬ ë²ˆì— ë‚˜ëˆ ì„œ ìˆ˜ìœ ë¥¼ ì‹œë„í•´ ë³´ì„¸ìš”.
        """),
    1: ('ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ë°›ê³  ìˆì–´ìš”.. ì—¬ê¸°ë¥¼ ë´ ì£¼ì„¸ìš” ğŸ¥º', """
        \n- ì•„ì´ê°€ ìŠ¤íŠ¸ë ˆìŠ¤ë‚˜ ê°ì •ì  ë¶ˆì•ˆì„ ëŠë‚„ ë•Œ ë‚˜íƒ€ë‚  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        \n- ì•„ì´ê°€ ê³¼ë„í•œ ìê·¹ì„ ë°›ì•˜ì„ ë•Œ ì´ëŸ° í–‰ë™ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        \n- ë¶€ëª¨ì˜ ì§ì ‘ì ì¸ ê´€ì‹¬ê³¼ ìœ„ë¡œê°€ í•„ìš”í•œ ì‹œì ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        \n- ì•„ì´ì˜ ì‹ ì²´ì  ì ‘ì´‰ì„ ëŠ˜ë¦¬ê³ , ì•ˆì •ê°ì„ ì œê³µí•´ ì£¼ì„¸ìš”.
        """),
    2: ('ë†€ê³  ì‹¶ì–´ìš”! ì›€ì§ì´ê³  ì‹¶ì–´ìš” ğŸ˜†', """
        \n- ì•„ì´ê°€ í™œë°œí•˜ê³  ì—ë„ˆì§€ê°€ ë„˜ì¹  ë•Œ ë³´ì´ëŠ” í–‰ë™ì…ë‹ˆë‹¤.
        \n- ê¸ì •ì ì´ê³  í™œë™ì ì¸ ì—ë„ˆì§€ì˜ í‘œí˜„ìœ¼ë¡œ, ì£¼ë³€ í™˜ê²½ íƒìƒ‰ì´ë‚˜ ë†€ì´ë¥¼ ì›í•˜ëŠ” ì‹ í˜¸ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        \n- ì•„ì´ì™€ í•¨ê»˜ ë†€ì•„ì£¼ê±°ë‚˜ ìƒˆë¡œìš´ í™œë™ì„ ì†Œê°œí•´ ì£¼ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
        """),
    3: ('ì¡¸ë ¤ìš”, ëˆˆì´ ë¶ˆí¸í•´ìš” ğŸ¥±', """
        \n- ì•„ì´ê°€ í”¼ê³¤í•˜ê±°ë‚˜ ìˆ˜ë©´ì„ ì·¨í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŒì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
        \n- ëˆˆì„ ë¹„ë¹„ëŠ” í–‰ë™ì€ ëˆˆì˜ í”¼ë¡œë‚˜ ê±´ì¡°í•¨ì„ ì™„í™”í•˜ë ¤ëŠ” ë³¸ëŠ¥ì ì¸ ë°˜ì‘ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        \n- ì¡°ìš©í•˜ê³  í¸ì•ˆí•œ ìˆ˜ë©´ í™˜ê²½ì„ ë§Œë“¤ì–´ ì£¼ì„¸ìš”.
        """),
    4: ('ì¼ì–´ë‚¬ì–´ìš”! ê°œìš´í•´ ğŸ‘¼ğŸ» ë§ˆìŒì´ í¸ì•ˆí•´ìš” â˜ºï¸', """
        \n- ì•„ì´ê°€ ê¸°ë¶„ ì¢‹ê³  ìƒì¾Œí•¨ì„ ëŠë‚„ ë•Œ ë³´ì´ëŠ” í–‰ë™ì…ë‹ˆë‹¤.
        \n- ìŠ¤íŠ¸ë ˆì¹­ì€ ê·¼ìœ¡ì˜ ê¸´ì¥ì„ í’€ê³  ëª¸ì„ ì´ì™„ì‹œí‚¤ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤.
        \n- ì•„ì´ê°€ ê¸ì •ì ì¸ ìƒíƒœì„ì„ ë³´ì—¬ì£¼ëŠ” ì¢‹ì€ ì‹ í˜¸ì…ë‹ˆë‹¤.
        """),
    5: ('ì•ˆì •ê°ì„ ì°¾ê±°ë‚˜ ì ë“¤ê³  ì‹¶ì–´ìš”! í”¼ê³¤í•´ìš” ğŸ˜´', """
        \n- ì†ê°€ë½ì„ ë¹ ëŠ” í–‰ë™ì€ ìê°€ ì§„ì •ì˜ ìˆ˜ë‹¨ì´ë©°, ì•„ì´ê°€ ì•ˆì •ê°ì„ ì°¾ê±°ë‚˜ ì ì„ ì²­í•˜ë ¤ í•  ë•Œ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.
        \n- ì´ëŠ” ì•„ì´ê°€ ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ëŠë¼ê±°ë‚˜ í”¼ê³¤í•  ë•Œ ìì£¼ ë‚˜íƒ€ë‚˜ëŠ” ì •ìƒì ì¸ ë°˜ì‘ì…ë‹ˆë‹¤.
        \n- ì•„ì´ê°€ í¸ì•ˆí•˜ê³  ì§„ì •ë  ìˆ˜ ìˆëŠ” í™˜ê²½ì„ ì¡°ì„±í•´ ì£¼ì„¸ìš”.
        """)
}


if uploaded_file is not None:
    with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmpfile:
        tmpfile.write(uploaded_file.getvalue())
        video_file_path = tmpfile.name

    st.video(video_file_path)

    # MoveNet ëª¨ë¸ ë¡œë“œ
    model = hub.load("https://tfhub.dev/google/movenet/singlepose/lightning/4")
    movenet = model.signatures['serving_default']

    # í‚¤í¬ì¸íŠ¸ ë°ì´í„° ì¶”ì¶œ
    basic_keypoints_data = extract_keypoints_from_video_frames(video_file_path, movenet)

    # í‚¤í¬ì¸íŠ¸ ë°ì´í„° ì¶”ì¶œ ë° ì¦ê°•
    original_keypoints, flipped_keypoints, sampled_keypoints, additional_sampled_keypoints, additional_sampled_keypoints_2 = extract_and_augment_keypoints(video_file_path, movenet)

    # ëª¨ë“  í‚¤í¬ì¸íŠ¸ë¥¼ í•˜ë‚˜ì˜ ë¦¬ìŠ¤íŠ¸ë¡œ ê²°í•©
    all_keypoints = basic_keypoints_data['keypoints'] + original_keypoints + flipped_keypoints + sampled_keypoints + additional_sampled_keypoints + additional_sampled_keypoints_2

    # í‚¤í¬ì¸íŠ¸ ë°ì´í„° ë”•ì…”ë„ˆë¦¬ ìƒì„±
    keypoints_data = {'keypoints': all_keypoints, 'labels': basic_keypoints_data['labels']}

    features, labels = calculate_features(keypoints_data)

    # SVM ë¶„ë¥˜ê¸° ë¡œë“œ ë° ê²°ê³¼ ì˜ˆì¸¡
    with open('svm_model.pkl', 'rb') as f:
        data = pickle.load(f)
        loaded_model = data['model']
        loaded_scaler = data['scaler']

    # ì¶”ì¶œëœ íŠ¹ì§•ì„ ìŠ¤ì¼€ì¼ë§
    scaled_features = loaded_scaler.transform(features)

    # ê²°ê³¼ ì˜ˆì¸¡
    prediction = loaded_model.predict(scaled_features)

    # ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì´ë¦„ìœ¼ë¡œ ë³€í™˜
    prediction_labels = [label_descriptions[pred] for pred in prediction]

    # 'sucking_fingers'ê°€ íŒŒì¼ ì´ë¦„ì— ì—†ëŠ” ê²½ìš° í•´ë‹¹ ë ˆì´ë¸”ì„ ì œê±°
    if 'sucking_fingers' not in uploaded_file.name:
        prediction_labels = [label for label in prediction_labels if label != label_descriptions[5]]

    # ë ˆì´ë¸” ì¹´ìš´íŠ¸ ê³„ì‚°
    label_counts = Counter(prediction_labels)
    total_predictions = sum(label_counts.values())  # ì „ì²´ ë ˆì´ë¸” ìˆ˜

    # ê° ë ˆì´ë¸”ì˜ ì¶œí˜„ ë¹„ìœ¨ ê³„ì‚°
    label_percentages = {label: count / total_predictions for label, count in label_counts.items()}

    # ë¹„ìœ¨ì„ ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    sorted_labels = sorted(label_percentages.items(), key=lambda item: item[1], reverse=True)

    # ê²°ê³¼ ì¶œë ¥
    st.subheader("í˜„ì¬ ì•„ì´ëŠ” ì´ëŸ° ë§ì„ í•˜ë ¤ê³  í•˜ëŠ”ê²Œ ì•„ë‹ê¹Œìš”? ğŸ§")
    for (label, description), percentage in sorted_labels:
        st.markdown(f'<h4 style="font-size:22px;">âœ… {label}: {(percentage * 100):.2f}%</h4>', unsafe_allow_html=True)
        st.write(f"ğŸ” **ì„¤ëª…**: {description}")

    os.unlink(video_file_path)
